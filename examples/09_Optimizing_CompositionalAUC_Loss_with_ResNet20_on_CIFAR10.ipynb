{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizing Compositional AUROC loss on imbalanced dataset**\n",
        " **Author**: Zhuoning Yuan"
      ],
      "metadata": {
        "id": "sEpAVQ2Fwhk1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUv-WIY5h1Dh"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "In this tutorial, we will learn how to quickly train a ResNet20 model by optimizing AUC score using our novel compositional training framework [[Ref]](https://openreview.net/forum?id=gPvB4pdu_Z) on an binary image classification task on Cifar10. After completion of this tutorial, you should be able to use LibAUC to train your own models on your own datasets.  \n",
        "\n",
        "**Useful Resources**\n",
        "\n",
        "* Website: https://libauc.org\n",
        "* Github: https://github.com/Optimization-AI/LibAUC\n",
        "\n",
        "\n",
        "**References**\n",
        "\n",
        "If you find this tutorial helpful in your work,  please acknowledge our library and cite the following papers:\n",
        "<pre>\n",
        "@inproceedings{yuan2022compositional,\n",
        "    title={Compositional Training for End-to-End Deep AUC Maximization},\n",
        "    author={Zhuoning Yuan and Zhishuai Guo and Nitesh Chawla and Tianbao Yang},\n",
        "    booktitle={International Conference on Learning Representations},\n",
        "    year={2022},\n",
        "    url={https://openreview.net/forum?id=gPvB4pdu_Z}\n",
        "}\n",
        "\n",
        "@misc{libauc2022,\n",
        "\ttitle={LibAUC: A Deep Learning Library for X-risk Optimization.},\n",
        "\tauthor={Zhuoning Yuan, Zi-Hao Qiu, Gang Li, Dixian Zhu, Zhishuai Guo, Quanqi Hu, Bokun Wang, Qi Qi, Yongjian Zhong, Tianbao Yang},\n",
        "\tyear={2022}\n",
        "\t}\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEavjKBdh8hF"
      },
      "source": [
        "# **Installing LibAUC**\n",
        "Let's start with install our library here. In this tutorial, we will use beta version `1.1.9rc3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zYjONxCh5Gz"
      },
      "outputs": [],
      "source": [
        "!pip install libauc==1.1.9rc3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m-DLkddiPT9"
      },
      "source": [
        "# **Importing LibAUC**\n",
        "\n",
        "Import required packages to use\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7oZv1TakiUBF"
      },
      "outputs": [],
      "source": [
        "from libauc.losses import CompositionalAUCLoss\n",
        "from libauc.optimizers import PDSCA\n",
        "from libauc.models import resnet20 as ResNet20\n",
        "from libauc.datasets import CIFAR10, CIFAR100, STL10, CAT_VS_DOG\n",
        "from libauc.utils import ImbalancedDataGenerator\n",
        "from libauc.sampler import DualSampler\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd57DCDOilVL"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function `set_all_seeds` limits the number of sources of randomness behaviors, such as model intialization, data shuffling, etcs. However, completely reproducible results are not guaranteed across PyTorch releases [[Ref]](https://pytorch.org/docs/stable/notes/randomness.html#:~:text=Completely%20reproducible%20results%20are%20not,even%20when%20using%20identical%20seeds.)."
      ],
      "metadata": {
        "id": "ndENFEtPKJk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-dUoQpz5imKD"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2wT1qzXiqCg"
      },
      "source": [
        "# **Image Dataset**\n",
        "\n",
        "\n",
        "Now that we defined the data input pipeline such as data augmentations. In this tutorials, we use `RandomCrop`, `RandomHorizontalFlip` as stated in the original paper. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kCEq4vNairrd"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3FgOKRPivmD"
      },
      "source": [
        "# **Hyperparameter Setting**\n",
        "\n",
        "Our target is to optimize the compositional loss: $\\min _{\\mathbf{w}} L_{\\mathrm{AUC}}\\left(\\mathbf{w}-\\alpha \\nabla L_{\\mathrm{CE}}(\\mathbf{w})\\right)$, which is implemented by `CompositionalAUCLoss()` function. In this function, it consists of both **CrossEntropy** and **AUC-Margin** Losses. \n",
        "\n",
        "Our optimization algorithm is called `PDSCA`, which is implemented by `PDSCA()` function. **PDSCA** is a momentum-style or adam-style stochastic gradient algorithms. The key updates are as follow: \n",
        "\n",
        "1.  $ \\mathbf{u}_{t+1}=(1-\\beta_{0}) \\mathbf{u}_{t}+\\beta_{0}(\\mathbf{w}_{\\mathbf{t}}-\\eta_0 \\nabla L_{CE}(\\mathbf{w}_{\\mathbf{t}}) ; a ; b)$ \n",
        "2. $ \\mathbf{z}_{t+1}=(1-\\beta_{1}) \\mathbf{z}_{t}+\\beta_{1} \\nabla_{\\mathbf{u}} L_{AUC}(\\mathbf{u}_{t+1})$ \n",
        "3. $ \\mathbf{w}_{t+1}=\\mathbf{w}_{t}-\\eta_{1} (\\mathbf{z}_{t+1}$ + $位_0(\\mathbf{w}_t-\\mathbf{w}_0)+ 位_1\\mathbf{w}_t$) \n",
        "4. $ \\theta_{t+1}=\\theta_{t}+\\eta_{2} \\nabla_{\\theta} L_{AUC}(\\theta_{t})$\n",
        "\n",
        "For more details about the algorithm, please refer to our paper [ref](https://openreview.net/pdf?id=gPvB4pdu_Z). Our implementation requires the following parameters:\n",
        "\n",
        "**Parameters:**\n",
        "\n",
        "- **DualSampler**:\n",
        "  - `batch_size`: mini batch size.\n",
        "  - `sampling_rate`: ratio of postive samples in a mini-batch\n",
        "  - `num_pos`: sample `num_pos` positive samples in a mini-batch\n",
        "\n",
        "- **Optimizer** (PDSCA):\n",
        "  - `lr`: initial learning rate for general optimization process.\n",
        "  - `lr0`: inital learning rate refers to $\\alpha$ in step (1). Default value is set to same value as `lr`. \n",
        "  - `margin`: margin term for AUC-M loss. We integrate this term in the optimizer instead of loss.\n",
        "  - `epoch_decay`: refers to $位_0$. Value for epoch regularizers. Default value is set to 0.002. \n",
        "  - `weight_decay`: refers to $位_1$. Value for l2 weight regularization term. Default value is 0.0001.\n",
        "  - `beta0`: parameter for moving average in step (1). Default value is 0.9. \n",
        "  - `beta1`: parameter for moving average in step (2). Default value is 0.999. \n",
        "\n",
        "\n",
        "**Useful Tips**\n",
        "- For better performance on imbalanced dataset, you can tune `num_pos` or `sampling_rate` in `DualSampler`.\n",
        "- Use smaller `lr0` and larger `lr` can achieve good performance in some cases. e.g., `lr0=0.05`, `lr=0.1`\n",
        "- Don not add `sigmoid` activation layer before loss function. The `CompositionalAUCLoss()` includes `sigmoid` by itself.\n",
        "- To manually update `lr` you can do `optimizer.param_groups[0]['lr'] = self.param_groups[0]['lr']/decay_factor`. Similar to `lr0`, you can modify `optimizer.param_groups[0]['lr0']`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "g8ReDBxeixFw"
      },
      "outputs": [],
      "source": [
        "# all paramaters\n",
        "total_epochs = 50 \n",
        "SEED = 123\n",
        "dataset = 'C100' # choose dataset to use\n",
        "imratio = 0.1\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# tunable paramaters\n",
        "margin = 1.0\n",
        "lr = 0.1  \n",
        "#lr0 = 0.1 # By default, lr0=lr unless you specify the value and pass it to optimizer\n",
        "epoch_decay = 5e-4 \n",
        "weight_decay = 1e-4\n",
        "beta0 = 0.9   # try different values: e.g., [0.999, 0.99, 0.9]\n",
        "beta1 = 0.999 # try different values: e.g., [0.999, 0.99, 0.9] \n",
        "\n",
        "# lr decay epochs \n",
        "decay_epochs=[int(total_epochs*0.5), int(total_epochs*0.75)] # decay learning rate at 50%, 75% epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmv9mBdvjA4l"
      },
      "source": [
        "# **Loading datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we will use the [CIFAR10](http://yann.lecun.com/exdb/mnist/) as benchmark dataset. Before importing data to `dataloader`, we construct imbalanced version for CIFAR10 by `ImbalanceGenerator`. Specifically, it first randomly splits the training data by class ID (e.g., 10 classes) into two even portions as the positive and negative classes, and then it randomly removes some samples from the positive class to make\n",
        "it imbalanced. We keep the testing set untouched. We refer `imratio` to the ratio of number of positive examples to number of all examples. "
      ],
      "metadata": {
        "id": "QqzyXxLvInZ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fCXryRjB1Z",
        "outputId": "983c9108-afdb-4e59-aaa8-284fbfe6df1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "#SAMPLES: [27777], POS:NEG: [2777 : 25000], POS RATIO: 0.1000\n",
            "#SAMPLES: [10000], POS:NEG: [5000 : 5000], POS RATIO: 0.5000\n"
          ]
        }
      ],
      "source": [
        "if dataset == 'C10':\n",
        "    IMG_SIZE = 32\n",
        "    train_data, train_targets = CIFAR10(root='./data', train=True)\n",
        "    test_data, test_targets  = CIFAR10(root='./data', train=False)\n",
        "elif dataset == 'C100':\n",
        "    IMG_SIZE = 32\n",
        "    train_data, train_targets = CIFAR100(root='./data', train=True)\n",
        "    test_data, test_targets  = CIFAR100(root='./data', train=False)\n",
        "elif dataset == 'STL10':\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = 96\n",
        "    train_data, train_targets = STL10(root='./data/', split='train')\n",
        "    test_data, test_targets = STL10(root='./data/', split='test')\n",
        "elif dataset == 'C2':\n",
        "    IMG_SIZE = 50\n",
        "    train_data, train_targets  = CAT_VS_DOG('./data/', train=True)\n",
        "    test_data, test_targets = CAT_VS_DOG('./data/', train=False)\n",
        "\n",
        "(train_images, train_labels) = ImbalancedDataGenerator(verbose=True, random_seed=0).transform(train_data, train_targets, imratio=imratio)\n",
        "(test_images, test_labels) = ImbalancedDataGenerator(verbose=True, random_seed=0).transform(test_data, test_targets, imratio=0.5) \n",
        "\n",
        "trainSet = ImageDataset(train_images, train_labels, image_size=IMG_SIZE, crop_size=IMG_SIZE-2)\n",
        "testSet = ImageDataset(test_images, test_labels, image_size=IMG_SIZE, crop_size=IMG_SIZE-2, mode='test')\n",
        "\n",
        "# parameters for sampler\n",
        "num_pos = 20\n",
        "sampler = DualSampler(trainSet, batch_size=BATCH_SIZE, num_pos=num_pos)\n",
        "trainloader = torch.utils.data.DataLoader(trainSet, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=False, drop_last=True)\n",
        "testloader = torch.utils.data.DataLoader(testSet, batch_size=BATCH_SIZE, shuffle=False, num_workers=8,  pin_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model, Loss & Optimizer**\n",
        "Before training, we need to define **model**, **loss function**, **optimizer**. "
      ],
      "metadata": {
        "id": "6GCtKxlBZnGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_all_seeds(123)\n",
        "model = ResNet20(pretrained=False, last_activation=None, activations='relu', num_classes=1)\n",
        "model = model.cuda()\n",
        "    \n",
        "# Compositional Training\n",
        "Loss = CompositionalAUCLoss()  \n",
        "optimizer = PDSCA(model, \n",
        "                  a=Loss.a, \n",
        "                  b=Loss.b, \n",
        "                  alpha=Loss.alpha, \n",
        "                  lr=lr,\n",
        "                  beta1=beta0,\n",
        "                  beta2=beta1, \n",
        "                  epoch_decay=epoch_decay, \n",
        "                  margin=margin, \n",
        "                  weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "rUmU3E60Zqzi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yreaM0sSjQj0"
      },
      "source": [
        "# **Training**\n",
        "Now it's time for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2cuzzOhh-NA",
        "outputId": "1729bd74-660d-47ba-d655-268141d0f2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "epoch: 0, train_auc:0.541168, test_auc:0.552227, test_auc_max:0.552227\n",
            "epoch: 1, train_auc:0.576345, test_auc:0.586668, test_auc_max:0.586668\n",
            "epoch: 2, train_auc:0.587045, test_auc:0.591103, test_auc_max:0.591103\n",
            "epoch: 3, train_auc:0.598651, test_auc:0.612225, test_auc_max:0.612225\n",
            "epoch: 4, train_auc:0.605189, test_auc:0.600635, test_auc_max:0.612225\n",
            "epoch: 5, train_auc:0.612469, test_auc:0.625973, test_auc_max:0.625973\n",
            "epoch: 6, train_auc:0.622305, test_auc:0.603082, test_auc_max:0.625973\n",
            "epoch: 7, train_auc:0.629492, test_auc:0.629510, test_auc_max:0.629510\n",
            "epoch: 8, train_auc:0.637966, test_auc:0.621774, test_auc_max:0.629510\n",
            "epoch: 9, train_auc:0.640338, test_auc:0.634803, test_auc_max:0.634803\n",
            "epoch: 10, train_auc:0.650294, test_auc:0.613869, test_auc_max:0.634803\n",
            "epoch: 11, train_auc:0.649819, test_auc:0.632193, test_auc_max:0.634803\n",
            "epoch: 12, train_auc:0.661654, test_auc:0.624435, test_auc_max:0.634803\n",
            "epoch: 13, train_auc:0.660682, test_auc:0.639569, test_auc_max:0.639569\n",
            "epoch: 14, train_auc:0.667060, test_auc:0.628926, test_auc_max:0.639569\n",
            "epoch: 15, train_auc:0.667200, test_auc:0.635505, test_auc_max:0.639569\n",
            "epoch: 16, train_auc:0.670945, test_auc:0.636655, test_auc_max:0.639569\n",
            "epoch: 17, train_auc:0.671258, test_auc:0.641494, test_auc_max:0.641494\n",
            "epoch: 18, train_auc:0.678309, test_auc:0.618804, test_auc_max:0.641494\n",
            "epoch: 19, train_auc:0.677337, test_auc:0.648105, test_auc_max:0.648105\n",
            "epoch: 20, train_auc:0.686327, test_auc:0.640987, test_auc_max:0.648105\n",
            "epoch: 21, train_auc:0.681154, test_auc:0.651852, test_auc_max:0.651852\n",
            "epoch: 22, train_auc:0.688805, test_auc:0.643461, test_auc_max:0.651852\n",
            "epoch: 23, train_auc:0.681067, test_auc:0.645354, test_auc_max:0.651852\n",
            "epoch: 24, train_auc:0.690101, test_auc:0.653198, test_auc_max:0.653198\n",
            "Reducing learning rate to 0.01000 (0.01000) @ T=5425!\n",
            "Updating regularizer @ T=5425!\n",
            "epoch: 25, train_auc:0.722556, test_auc:0.675511, test_auc_max:0.675511\n",
            "epoch: 26, train_auc:0.736514, test_auc:0.676931, test_auc_max:0.676931\n",
            "epoch: 27, train_auc:0.741784, test_auc:0.680236, test_auc_max:0.680236\n",
            "epoch: 28, train_auc:0.747322, test_auc:0.679851, test_auc_max:0.680236\n",
            "epoch: 29, train_auc:0.747413, test_auc:0.681994, test_auc_max:0.681994\n",
            "epoch: 30, train_auc:0.755034, test_auc:0.681636, test_auc_max:0.681994\n",
            "epoch: 31, train_auc:0.757188, test_auc:0.683104, test_auc_max:0.683104\n",
            "epoch: 32, train_auc:0.760717, test_auc:0.682031, test_auc_max:0.683104\n",
            "epoch: 33, train_auc:0.764296, test_auc:0.682744, test_auc_max:0.683104\n",
            "epoch: 34, train_auc:0.768730, test_auc:0.680619, test_auc_max:0.683104\n",
            "epoch: 35, train_auc:0.771792, test_auc:0.682266, test_auc_max:0.683104\n",
            "epoch: 36, train_auc:0.770047, test_auc:0.682122, test_auc_max:0.683104\n",
            "Reducing learning rate to 0.00100 (0.00100) @ T=8029!\n",
            "Updating regularizer @ T=8029!\n",
            "epoch: 37, train_auc:0.783289, test_auc:0.684234, test_auc_max:0.684234\n",
            "epoch: 38, train_auc:0.785507, test_auc:0.683823, test_auc_max:0.684234\n",
            "epoch: 39, train_auc:0.787542, test_auc:0.684795, test_auc_max:0.684795\n",
            "epoch: 40, train_auc:0.791189, test_auc:0.683943, test_auc_max:0.684795\n",
            "epoch: 41, train_auc:0.789258, test_auc:0.685458, test_auc_max:0.685458\n",
            "epoch: 42, train_auc:0.790119, test_auc:0.684093, test_auc_max:0.685458\n",
            "epoch: 43, train_auc:0.789863, test_auc:0.684961, test_auc_max:0.685458\n",
            "epoch: 44, train_auc:0.791594, test_auc:0.684327, test_auc_max:0.685458\n",
            "epoch: 45, train_auc:0.790824, test_auc:0.685216, test_auc_max:0.685458\n",
            "epoch: 46, train_auc:0.796223, test_auc:0.684843, test_auc_max:0.685458\n",
            "epoch: 47, train_auc:0.791938, test_auc:0.685669, test_auc_max:0.685669\n",
            "epoch: 48, train_auc:0.795143, test_auc:0.685057, test_auc_max:0.685669\n",
            "epoch: 49, train_auc:0.794301, test_auc:0.685537, test_auc_max:0.685669\n"
          ]
        }
      ],
      "source": [
        "train_list = []\n",
        "test_list = []\n",
        "\n",
        "test_auc_max = 0\n",
        "print ('-'*30)\n",
        "for epoch in range(total_epochs):\n",
        "    if epoch in decay_epochs:\n",
        "      optimizer.update_regularizer(decay_factor=10)\n",
        "\n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    for idx, (data, targets) in enumerate(trainloader):\n",
        "        model.train()  \n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        loss = Loss(y_pred, targets) # don't include sigmoid in this loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(y_pred.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "    \n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    train_auc = roc_auc_score(train_true, train_pred) \n",
        "    \n",
        "    # evaluations\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for j, data in enumerate(testloader):\n",
        "        test_data, test_targets = data\n",
        "        test_data = test_data.cuda()\n",
        "        outputs = model(test_data)\n",
        "        y_pred = torch.sigmoid(outputs)\n",
        "        test_pred.append(y_pred.cpu().detach().numpy())\n",
        "        test_true.append(test_targets.numpy())\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "    val_auc =  roc_auc_score(test_true, test_pred) \n",
        "    model.train()\n",
        "\n",
        "\n",
        "    train_list.append(train_auc)\n",
        "    test_list.append(val_auc)\n",
        "\n",
        "    if test_auc_max<val_auc:\n",
        "       test_auc_max = val_auc\n",
        "      \n",
        "    # print results\n",
        "    print(\"epoch: {}, train_auc:{:4f}, test_auc:{:4f}, test_auc_max:{:4f}\".format(epoch, train_auc, val_auc, test_auc_max, optimizer.lr ))          "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualization**\n",
        "\n",
        "Now, let's see the change of AUC scores on training and testing set. \n"
      ],
      "metadata": {
        "id": "VVGuukZ0FpfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Comparsion of CE/AUC\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_list, label='train')\n",
        "plt.plot(test_list, label='test')\n",
        "plt.title('AUC Score Over Time')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('AUROC')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CoM4Tnl0LmfY",
        "outputId": "127b73ad-836b-42ff-ef34-3cb7f7a49b9f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "09_Optimizing_CompositionalAUC_Loss_with_ResNet20_on_CIFAR10.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}