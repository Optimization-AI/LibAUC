{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06_Optimizing_Multi_Label_AUROC_Loss_with_DenseNet121_on_CheXpert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qkb6bYy3rOx"
      },
      "source": [
        "\n",
        "\n",
        "* Author: Zhuoning Yuan\n",
        "* Project: https://github.com/Optimization-AI/LibAUC/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTJ3ca0u4YQ4"
      },
      "source": [
        "# **Installing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8iVw1kU3guh"
      },
      "source": [
        "!pip install libauc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlD-4SrE4dVW"
      },
      "source": [
        "# **Downloading CheXpert**\n",
        " \n",
        "*   To request dataset access, you need to apply from CheXpert website: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
        "*   In this tutorial, we use the smaller version of dataset with lower image resolution, i.e., *CheXpert-v1.0-small.zip*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcsJ4eoj3VST"
      },
      "source": [
        "!cp /content/drive/MyDrive/chexpert-dataset/CheXpert-v1.0-small.zip /content/\n",
        "!mkdir CheXpert\n",
        "!unzip CheXpert-v1.0-small.zip -d /content/CheXpert/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVvrt3ku4qpq"
      },
      "source": [
        "\n",
        "# **Importing LibAUC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGHWer3v4qJo"
      },
      "source": [
        "from libauc.losses import AUCM_MultiLabel, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.models import DenseNet121, DenseNet169\n",
        "from libauc.datasets import CheXpert\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch.nn.functional as F   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2swK5Mo7Kca"
      },
      "source": [
        "# **Reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiiT5oEp7J3C"
      },
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3Bge6KM7lBP"
      },
      "source": [
        "# **Multi-Label Training**\n",
        "* Optimizing Multi-Label AUC (5 tasks)   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6p0oVY8AouP",
        "outputId": "84e1b914-1327-4d6a-dde0-5f4abc0eaf54"
      },
      "source": [
        "# dataloader\n",
        "root = './CheXpert/CheXpert-v1.0-small/'\n",
        "# Index: -1 denotes multi-label mode including 5 diseases\n",
        "traindSet = CheXpert(csv_path=root+'train.csv', image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='train', class_index=-1, verbose=False)\n",
        "testSet =  CheXpert(csv_path=root+'valid.csv',  image_root_path=root, use_upsampling=False, use_frontal=True, image_size=224, mode='valid', class_index=-1, verbose=False)\n",
        "trainloader =  torch.utils.data.DataLoader(traindSet, batch_size=32, num_workers=2, shuffle=True)\n",
        "testloader =  torch.utils.data.DataLoader(testSet, batch_size=32, num_workers=2, shuffle=False)\n",
        "\n",
        "# paramaters\n",
        "SEED = 123\n",
        "BATCH_SIZE = 32\n",
        " \n",
        "lr = 0.1 # using smaller learning rate is better\n",
        "gamma = 500\n",
        "imratio = traindSet.imratio_list \n",
        "weight_decay = 1e-5\n",
        "margin = 1.0\n",
        "\n",
        "# model\n",
        "set_all_seeds(SEED)\n",
        "model = DenseNet121(pretrained=True, last_activation=None, activations='relu', num_classes=5)\n",
        "model = model.cuda()\n",
        "\n",
        "# define loss & optimizer\n",
        "Loss = AUCM_MultiLabel(imratio=imratio, num_classes=5)\n",
        "optimizer = PESG(model, \n",
        "                 a=Loss.a, \n",
        "                 b=Loss.b, \n",
        "                 alpha=Loss.alpha, \n",
        "                 lr=lr, \n",
        "                 gamma=gamma, \n",
        "                 margin=margin, \n",
        "                 weight_decay=weight_decay, device='cuda')\n",
        "\n",
        "\n",
        "# training\n",
        "best_val_auc = 0 \n",
        "for epoch in range(2):\n",
        "    if epoch > 0:\n",
        "        optimizer.update_regularizer(decay_factor=10)       \n",
        "    for idx, data in enumerate(trainloader):\n",
        "      train_data, train_labels = data\n",
        "      train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
        "      y_pred = model(train_data)\n",
        "      y_pred = torch.sigmoid(y_pred)\n",
        "      loss = Loss(y_pred, train_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "      # validation  \n",
        "      if idx % 400 == 0:\n",
        "         model.eval()\n",
        "         with torch.no_grad():    \n",
        "              test_pred = []\n",
        "              test_true = [] \n",
        "              for jdx, data in enumerate(testloader):\n",
        "                  test_data, test_labels = data\n",
        "                  test_data = test_data.cuda()\n",
        "                  y_pred = model(test_data)\n",
        "                  y_pred = torch.sigmoid(y_pred)\n",
        "                  test_pred.append(y_pred.cpu().detach().numpy())\n",
        "                  test_true.append(test_labels.numpy())\n",
        "            \n",
        "              test_true = np.concatenate(test_true)\n",
        "              test_pred = np.concatenate(test_pred)\n",
        "              val_auc_mean =  roc_auc_score(test_true, test_pred) \n",
        "              model.train()\n",
        "\n",
        "              if best_val_auc < val_auc_mean:\n",
        "                 best_val_auc = val_auc_mean\n",
        "                 torch.save(model.state_dict(), 'aucm_multi_label_pretrained_model.pth')\n",
        "\n",
        "              print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0, BatchID=0, Val_AUC=0.5632, Best_Val_AUC=0.5632\n",
            "Epoch=0, BatchID=400, Val_AUC=0.8233, Best_Val_AUC=0.8233\n",
            "Epoch=0, BatchID=800, Val_AUC=0.8075, Best_Val_AUC=0.8233\n",
            "Epoch=0, BatchID=1200, Val_AUC=0.8331, Best_Val_AUC=0.8331\n",
            "Epoch=0, BatchID=1600, Val_AUC=0.8020, Best_Val_AUC=0.8331\n",
            "Epoch=0, BatchID=2000, Val_AUC=0.8461, Best_Val_AUC=0.8461\n",
            "Epoch=0, BatchID=2400, Val_AUC=0.8446, Best_Val_AUC=0.8461\n",
            "Epoch=0, BatchID=2800, Val_AUC=0.8636, Best_Val_AUC=0.8636\n",
            "Epoch=0, BatchID=3200, Val_AUC=0.8734, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=3600, Val_AUC=0.8403, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=4000, Val_AUC=0.8321, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=4400, Val_AUC=0.8377, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=4800, Val_AUC=0.8577, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=5200, Val_AUC=0.8587, Best_Val_AUC=0.8734\n",
            "Epoch=0, BatchID=5600, Val_AUC=0.8708, Best_Val_AUC=0.8734\n",
            "Reducing learning rate to 0.01000 @ T=5970!\n",
            "Updating regularizer @ T=5970!\n",
            "Epoch=1, BatchID=0, Val_AUC=0.8601, Best_Val_AUC=0.8734\n",
            "Epoch=1, BatchID=400, Val_AUC=0.8896, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=800, Val_AUC=0.8857, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=1200, Val_AUC=0.8859, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=1600, Val_AUC=0.8890, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=2000, Val_AUC=0.8891, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=2400, Val_AUC=0.8801, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=2800, Val_AUC=0.8842, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=3200, Val_AUC=0.8888, Best_Val_AUC=0.8896\n",
            "Epoch=1, BatchID=3600, Val_AUC=0.8901, Best_Val_AUC=0.8901\n",
            "Epoch=1, BatchID=4000, Val_AUC=0.8849, Best_Val_AUC=0.8901\n",
            "Epoch=1, BatchID=4400, Val_AUC=0.8768, Best_Val_AUC=0.8901\n",
            "Epoch=1, BatchID=4800, Val_AUC=0.8886, Best_Val_AUC=0.8901\n",
            "Epoch=1, BatchID=5200, Val_AUC=0.8901, Best_Val_AUC=0.8901\n",
            "Epoch=1, BatchID=5600, Val_AUC=0.8851, Best_Val_AUC=0.8901\n"
          ]
        }
      ]
    }
  ]
}